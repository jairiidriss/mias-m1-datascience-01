{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc3be9a",
   "metadata": {},
   "source": [
    "## Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a360e917",
   "metadata": {},
   "source": [
    "<b>Imagine this situation:</b> You've developed a machine learning model that shows excellent accuracy on both your training and test sets. You're confident in its performance. However, when you deploy the model and it encounters new, real-world data, the results are surprisingly poor.\n",
    "What's going on here? How can this be happening when the accuracy was high for both training and test sets?<br>\n",
    "The likely problem/issue in this scenario is data leakage. Data leakage occurs when information that wouldn't be available in real-world situations sneaks into your model training process, leading to artificially inflated performance metrics during development but poor generalization when faced with truly new data.<br>\n",
    "This situation highlights why it's crucial to not only look at accuracy metrics but also to thoroughly understand your data, carefully design your validation strategy, and be vigilant about potential sources of leakage throughout the entire machine learning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4934d",
   "metadata": {},
   "source": [
    "### Common Types of Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620fb977",
   "metadata": {},
   "source": [
    "#### Target leakage: Using future information to predict the past"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b6859",
   "metadata": {},
   "source": [
    "Example: Predicting whether a patient will be diagnosed with a disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af609d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'symptoms', 'medication_prescribed']\n",
    "target = 'disease_diagnosis'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76f9f4",
   "metadata": {},
   "source": [
    "The feature 'medication_prescribed' is target leakage because it's information that would only be available after the diagnosis (our target variable) is made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a0af8",
   "metadata": {},
   "source": [
    "##### How to avoid target leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500da49",
   "metadata": {},
   "source": [
    "<b>Understand your data:</b> Carefully examine each feature and consider whether it would be available at the time of prediction in a real-world scenario.<br>\n",
    "<b>Use domain knowledge:</b> Consult with subject matter experts to identify potential leaky features.<br>\n",
    "<b>Feature creation care:</b> When engineering new features, be mindful of not incorporating future information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf98df",
   "metadata": {},
   "source": [
    "#### Train-test contamination: Test data influences the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d867b",
   "metadata": {},
   "source": [
    "Example: Using all data for feature scaling before splitting into train and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorrect approach (leakage)\n",
    "X_scaled = scale(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "\n",
    "# Correct approach\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train_scaled = scale(X_train)\n",
    "X_test_scaled = scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0181094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def scale(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    return (X - mean) / std\n",
    "\n",
    "# Also return mean and std for demonstration purposes\n",
    "def scale_with_params(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    return (X - mean) / std, mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32bec4b",
   "metadata": {},
   "source": [
    "##### Incorrect approach (data leakage):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f2afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scale(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cf52ce",
   "metadata": {},
   "source": [
    "This approach scales the entire dataset before splitting. The problem here is that the scaling operation uses information from all the data, including what will become the test set. This means that information from the test set (which should be completely unseen) is influencing how the training data is scaled, leading to data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e54f9",
   "metadata": {},
   "source": [
    "##### Correct approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1087ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train_scaled = scale(X_train)\n",
    "X_test_scaled = scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f923a5",
   "metadata": {},
   "source": [
    "This approach first splits the data, then scales the training and test sets separately. However, there's still an issue here: the test set is being scaled independently of the training set, which isn't ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74722a6",
   "metadata": {},
   "source": [
    "##### The truly correct approach would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train_scaled, train_mean, train_std = scale_with_params(X_train)\n",
    "X_test_scaled = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e5f974",
   "metadata": {},
   "source": [
    "This method:\n",
    "\n",
    "Splits the data first.\n",
    "Computes the scaling parameters (mean and std) using only the training data.\n",
    "Applies these same parameters to scale both the training and test data.\n",
    "\n",
    "This ensures that:\n",
    "\n",
    "No information from the test set influences the scaling of the training set.\n",
    "The test set is scaled in exactly the same way as the training set, mimicking how new, unseen data would be processed in a real-world scenario.\n",
    "\n",
    "By using this approach, we maintain the integrity of our test set as a true representation of unseen data, providing a more reliable estimate of our model's performance on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1765f9",
   "metadata": {},
   "source": [
    "##### Using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets first\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler only on the training data and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Use the same scaler (fitted on training data) to transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
